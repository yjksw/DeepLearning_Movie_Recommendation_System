{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 import\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./ml-latest-small/ratings.csv')\n",
    "print(data.shape)\n",
    "\n",
    "np.random.seed(3)\n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "train = data[msk].copy()\n",
    "val = data[~msk].copy()\n",
    "#test = data[~msk].copy()\n",
    "\n",
    "print(train.head())\n",
    "print(train.shape)\n",
    "print(val.head())\n",
    "print(val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_col(col, train_col=None):\n",
    "    \"\"\" Encodes a pandas column with continous ids. \"\"\"\n",
    "    if train_col is not None:\n",
    "        uniq = train_col.unique()\n",
    "    else:\n",
    "        uniq = col.unique()\n",
    "    name2idx = {o:i for i,o in enumerate(uniq)}\n",
    "    return name2idx, np.array([name2idx.get(x, -1) for x in col]), len(uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(df, train=None):\n",
    "    \"\"\" Encodes rating data with continous user and movie ids.\n",
    "    If train is provided, encodes df with the same encoding as train.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    for col_name in [\"userId\", \"movieId\"]:\n",
    "        train_col = None\n",
    "        if train is not None:\n",
    "            train_col = train[col_name]\n",
    "        n2i,col,len_uniq = proc_col(df[col_name], train_col)\n",
    "        df[col_name] = col\n",
    "        df = df[df[col_name] >= 0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the train and validation data\n",
    "df_train = encode_data(train)\n",
    "df_val = encode_data(val, train)\n",
    "#df_test = encode_data(test, train)\n",
    "\n",
    "num_users = len(df_train.userId.unique())\n",
    "num_items = len(df_train.movieId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loss(model, unsqueeze=False):\n",
    "    model.eval()\n",
    "    users = torch.LongTensor(df_val.userId.values)\n",
    "    items = torch.LongTensor(df_val.movieId.values)\n",
    "    ratings = torch.FloatTensor(df_val.rating.values)\n",
    "    if unsqueeze:\n",
    "        ratings = ratings.unsqueeze(1)\n",
    "    y_hat = model(users, items)\n",
    "    print(\"y_hat :\", y_hat, \",\", y_hat.shape)\n",
    "    loss = F.mse_loss(y_hat, ratings)\n",
    "    print(\"validation loss {:.3f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mf(model, epochs=10, lr=0.01, wd=0.0, unsqueeze=False):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    model.train()\n",
    "    print(\"Train,\", \"Learning Rate :\", lr)\n",
    "    for i in range(epochs):\n",
    "        users = torch.LongTensor(df_train.userId.values)\n",
    "        items = torch.LongTensor(df_train.movieId.values)\n",
    "        ratings = torch.FloatTensor(df_train.rating.values)\n",
    "        if unsqueeze:\n",
    "            ratings = ratings.unsqueeze(1)\n",
    "        y_hat = model(users, items)\n",
    "        loss = F.mse_loss(y_hat, ratings)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i%5 == 4:\n",
    "            print(\"epoch\", i+1, \":\", loss.item())\n",
    "    print(\"Valid\")\n",
    "    validation_loss(model, unsqueeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, userId=1, size=5):\n",
    "    print(\"Test\")\n",
    "    model.eval()\n",
    "    global df_test\n",
    "    \n",
    "    #특정 사용자 추출 \n",
    "    target_usr = df_test['userId'] == userId\n",
    "    target_df = df_test[target_usr]\n",
    "    users = torch.LongTensor(target_df.userId.values)\n",
    "    items = torch.LongTensor(target_df.movieId.values)\n",
    "    y_hat = model(users, items)\n",
    "\n",
    "    #y_hat(tensor)를 predictions(pandas dataframe)으로 변환\n",
    "    predictions = y_hat.detach().numpy()\n",
    "    predictions = pd.DataFrame(predictions)\n",
    "    predictions.columns = [\"predictions\"]\n",
    "\n",
    "    #df_test(dataframe)에 predictions 붙이기 => new_df\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "    new_df = pd.concat([df_test, predictions], axis=1)\n",
    "\n",
    "    #movie 이름 붙이기\n",
    "    movies = pd.read_csv('./ml-latest-small/movies.csv')\n",
    "    new_df = pd.merge(new_df, movies, on='movieId')\n",
    "\n",
    "    #predictions로 sort\n",
    "    new_df = new_df.sort_values(by=\"predictions\", ascending=False)\n",
    "\n",
    "\n",
    "    #size만큼만 남기기\n",
    "    new_df = new_df[:size]\n",
    "    #print()\n",
    "    #print(\"size\")\n",
    "    #print(new_df)\n",
    "\n",
    "    #결과 출력\n",
    "    result = []\n",
    "    new_df = new_df.reset_index(drop=True)\n",
    "    print()\n",
    "    print(\"Movie Recommendation for User\", userId)\n",
    "    for i in range(len(new_df)):\n",
    "        result.append(new_df[\"title\"][i])\n",
    "        print(i+1, \":\", result[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNCollabFiltering(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100, n_hidden=10):\n",
    "        super(NNCollabFiltering, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        self.lin1 = nn.Linear(emb_size*2, n_hidden)\n",
    "        self.lin2 = nn.Linear(n_hidden, 1)\n",
    "        self.drop1 = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, u, v):\n",
    "        U = self.user_emb(u)\n",
    "        V = self.item_emb(v)\n",
    "        x = F.relu(torch.cat([U, V], dim=1))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NNCollabFiltering(num_users, num_items, emb_size=100)\n",
    "# train_mf(model, epochs=50, lr=0.01, wd=1e-6, unsqueeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NNCollabFiltering(num_users, num_items, emb_size=100)\n",
    "train_mf(model, epochs=30, lr=0.05, wd=1e-6, unsqueeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NNCollabFiltering(num_users, num_items, emb_size=100)\n",
    "# train_mf(model, epochs=50, lr=0.001, wd=1e-6, unsqueeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, 5, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
